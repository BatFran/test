---
title: pa3
author: "Francisco Orejarena"
date: "February 20, 2018"
output: 
  html_document: 
    highlight: tango
    theme: cosmo
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Third Assignment

I timed this very very poorly, so I am using the regression practice we did in class as a template.

The following is the data that I am choosing to discuss.

```{r, my_setup, echo=TRUE, message=FALSE}
library(languageR)
library(tidyverse)
str(beginningReaders)


```

This data contains a lot of information, but for the purpose (and ease) of this, I am focusing on the frequency, and the length of the tokens of the data. My prediction is that there is a negative correlation between the frequency of a token in reading for Dutch children and its percent error in reconginition and response to the word (response in this case not being expanded or explained).

#Tidy?

Tidying for my data seems unecessary and excessive, as the two variables themselves are sufficient and seem clean enough.

```{r, my_plot, fig.align='center'}
my_data <- beginningReaders %>%
  select(., x = LogFrequency, y =  ProportionOfErrors)

my_data %>%
  ggplot(., aes(x = x, y = y)) +
    geom_point() +
    geom_smooth(method = 'lm')
```

# Models

Here, using the frameworks and codes that we used last week, I fit the dataseto in models that we discussed.

```{r, my_model}
my_fit <- lm(y ~ x, data = my_data)
summary(my_fit)
```

```{r}
confint(my_fit)
```

Their data were seemingly random; however, with the fitting of the line, there seems to be a negative correlation. That is, as the frequency of the word increasses, there seems to be less error in readability. This is understandable, as the more frequent something appears, the less foreign it seems to the agent of the situation.


  Slope: `r coefficients(my_fit)[2]`
```{r}
coefficients(my_fit)
```

```{r}

hist(residuals(my_fit))
qqnorm(residuals(my_fit))
qqline(residuals(my_fit))
```

```{r}
my_data %>%
  summary(.)
```
